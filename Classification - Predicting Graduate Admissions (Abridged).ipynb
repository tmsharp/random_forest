{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Predicting Graduate Admissions using Random Forest*\n",
    "#### Authors: Tom Sharp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Agenda ##\n",
    "Part 1: Data Import, Exploration, and Cleaning <br>\n",
    "Part 2: Decision Tree - The Building Block of Random Forest <br>\n",
    "Part 3: Random Forest <br>\n",
    "Part 4: Feature Importance <br>\n",
    "Part 5: Over/Under Fitting <br>\n",
    "Part 6: Tuning the Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data for this notebook was obtained at https://www.kaggle.com/malapatiravi/graduate-school-admission-data '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Data for this notebook was obtained at {} \".format('https://www.kaggle.com/malapatiravi/graduate-school-admission-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os library, the pandas library (aliased as pd), the numpy library (aliased as np), \n",
    "# matplotlib.pyplot (aliased as plt), and pickle\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomsharp\\Desktop\\Firm Initiatives\\Demystifying_ML\\random_forest\n",
      "C:\\Users\\tomsharp\\Desktop\\Firm Initiatives\\Demystifying_ML\\random_forest\\data\\college_admissions.csv\n",
      "C:\\Users\\tomsharp\\Desktop\\Firm Initiatives\\Demystifying_ML\\random_forest\\images\n"
     ]
    }
   ],
   "source": [
    "# Store the paths to frequently used files\n",
    "\n",
    "parent_path = os.getcwd()\n",
    "data_path = os.path.join(parent_path,  'data', 'college_admissions.csv')\n",
    "image_path = os.path.join(parent_path, 'images')\n",
    "\n",
    "\n",
    "print(parent_path)\n",
    "print(data_path)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Import, Exploration, and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During any analysis, it is always important to first examine your data. This involves looking at the data itself, the column names, and some summary statistics about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data using the pandas package. The data is stored in what is called a dataframe (similar to a spreadsheet)\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rows, num of columns =  (400, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gre   gpa  rank  admit\n",
       "0  380  3.61     3      0\n",
       "1  660  3.67     3      1\n",
       "2  800  4.00     1      1\n",
       "3  640  3.19     4      1\n",
       "4  520  2.93     4      0\n",
       "5  760  3.00     2      1\n",
       "6  560  2.98     1      1\n",
       "7  400  3.08     2      0\n",
       "8  540  3.39     3      1\n",
       "9  700  3.92     2      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine number of rows and columns \n",
    "print(\"num of rows, num of columns = \", data.shape)\n",
    "\n",
    "# That's a lot of rows. Let's just look at the first three columns of the data, instead of all of them\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these column names could be a bit more specific - let's rename them\n",
    "data.columns = ['gre_score', 'undergrad_gpa', 'undergrad_school_rank', 'admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gre_score  undergrad_gpa  undergrad_school_rank    admitted\n",
      "count  400.000000     400.000000              400.00000  400.000000\n",
      "mean   587.700000       3.389900                2.48500    0.317500\n",
      "std    115.516536       0.380567                0.94446    0.466087\n",
      "min    220.000000       2.260000                1.00000    0.000000\n",
      "25%    520.000000       3.130000                2.00000    0.000000\n",
      "50%    580.000000       3.395000                2.00000    0.000000\n",
      "75%    660.000000       3.670000                3.00000    1.000000\n",
      "max    800.000000       4.000000                4.00000    1.000000\n",
      "\n",
      "\n",
      "Number of students admitted = 127\n",
      "Number of students NOT admitted (rejected) = 273\n"
     ]
    }
   ],
   "source": [
    "# We can view summary statistics about the data by calling the \"describe()\" method of \"data\"\n",
    "# Def: Method - take an action on the data (a verb)\n",
    "\n",
    "print(data.describe())\n",
    "print('\\n')\n",
    "print(\"Number of students admitted = {}\".format(sum(data['admitted']==1)))\n",
    "print(\"Number of students NOT admitted (rejected) = {}\".format(sum(data['admitted']==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**This first value, *admitted*, is what we would like to predict using a machine learning.** \n",
    "\n",
    "Before we can predict, we need to make sure we clean the data. Fortunately, someone cleaned this dataset for us already.\n",
    "<br>\n",
    "*Note - In most applications of data science and ML, we would take a closer look at cleaning the data. Data gathering and cleansing usually consumes 80%+ of the DS/ML process; however, this dataset happened to be extremely clean when it was retrieved from its source online.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Decision Tree - The Building Block of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tree_joke.jpg\" height=\"500\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the columns to be used as inputs (X) are referred to as the **features**, and the output (y) value is referred to as the **target** or the **label**.\n",
    "<br>\n",
    "\n",
    "Since we are given the target/label values in this dataset, the type of machine learning we will be doing is called **supervised**. \n",
    "<br>\n",
    "In particular, we will be using a random forest. Before we jump into that, we need to understand the basic building block of that model, known as the decision tree. \n",
    "<br>\n",
    "<br>\n",
    "A decision tree is one of the easiest machine learning model to comprehend, since it is easily visualized. The below graphic is an example of a simple decision tree. Notice that each *node* contains a yes/no question, and each *branch* leads to a new node, unless it leads to an answer. These answers are called *leaves* or *leaf nodes*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/decision_tree_example.jpg\" width=\"500\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are these questions determined? The decision tree is given several features (inputs) and determines which questions to ask to *gain the most information from the oucome*, i.e., to increase **information gain**. You can think of a decision tree like a game of *Guess Who?*. Each round, you ask one question in order to get the most information out of the opposite player. \n",
    "<br>\n",
    "<br>\n",
    "For example, a popular first round question is, *\"Is your character a man or woman?\"*. This gives you a lot more information than asking *\"Is your character Joe?\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/guess_who.jpg\" width=\"500\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform supervised learning, we will **train** (aka, fit) our model, and then **test** our model to see how accurate it is. We do this by first dividing the data into the **training data** and the **testing data**. In order for our model to be trained adequately, we would like it to have as much data as possible. Therefore, we take 80% of our current dataset to be the training data, and the remaining 20% to be the testing data. This is somewhat arbitrary, but the split usually lies around 75 / 25 or 80 / 20. \n",
    "<br>\n",
    "\n",
    "Also recall from above that the input (X) values are referred to as **features** and the output (y) values are referred to as **targets** or **labels**. We need to store the columns in our dataset into these variables before we can split our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/splitting_data.png\" width=\"700\" height=\"700\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first split our data into **feaures** and **labels**, and then **training data** and **testing data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Features vs. Labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Features are: ['gre_score', 'undergrad_gpa', 'undergrad_school_rank']\n",
      "Our Label is:     ['admitted']\n"
     ]
    }
   ],
   "source": [
    "print(\"Our Features are: {}\".format(list(data.columns[0:3])))\n",
    "print(\"Our Label is:     {}\".format([data.columns[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES\n",
      "shape:  \n",
      " (400, 3)\n",
      "first five rows:  \n",
      " [[380.     3.61   3.  ]\n",
      " [660.     3.67   3.  ]\n",
      " [800.     4.     1.  ]\n",
      " [640.     3.19   4.  ]\n",
      " [520.     2.93   4.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays - these are similar to dataframes but have less structure. sklearn can only take numpy arrays\n",
    "\n",
    "# Drop the cmedv column - the features are all the columns except this one\n",
    "feature_names = ['gre_score', 'undergrad_gpa', 'undergrad_school_rank']\n",
    "features = data[feature_names]\n",
    "features = np.array(features)\n",
    "\n",
    "\n",
    "print(\"FEATURES\")\n",
    "print(\"shape: \", \"\\n\", features.shape)\n",
    "print(\"first five rows: \", \"\\n\", features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELS\n",
      "shape:  \n",
      " (400,)\n",
      "first five rows: \n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all columns that aren't cmedv - cmedv is the only label\n",
    "label_names = ['admitted']\n",
    "labels = data[label_names]\n",
    "labels = np.array(labels)\n",
    "labels = labels.reshape([400,])\n",
    "\n",
    "print(\"LABELS\")\n",
    "print(\"shape: \", \"\\n\", labels.shape)\n",
    "print(\"first five rows: \")\n",
    "[print(lab) for lab in labels[0:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training Data vs. Testing Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to split the data and store the data into variables. \n",
    "# Notice we specify test_size = 0.2. This gives the 80/20 split as explained above\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Supervised Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, a decision tree is a supervised learnin model, since we have labels that help the algorithm learn. The following picture depicts the supervised learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Supervised_Learning.png\" width=\"700\" height=\"700\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sci-kit learn 3 lines of code to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn import tree\n",
    "\n",
    "# instantiate \n",
    "decision_tree = tree.DecisionTreeClassifier(random_state = 8)\n",
    "\n",
    "# train/fit\n",
    "decision_tree = decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our *Trained Model* looks like by converting the tree into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View picture after converting to png (I did this for you already)\n",
    "# !\"images/tree_clf.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the labels from the testing data to generate predictions on the admissions. Let's see what the model comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted value</th>\n",
       "      <th>actual value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted value  actual value\n",
       "0                0             0\n",
       "1                1             0\n",
       "2                0             0\n",
       "3                0             1\n",
       "4                0             0\n",
       "5                0             0\n",
       "6                0             1\n",
       "7                1             0\n",
       "8                1             0\n",
       "9                0             1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "tree_predictions = decision_tree.predict(X_test)\n",
    "\n",
    "# Format and print\n",
    "tree_predictions = pd.Series(tree_predictions)\n",
    "pd.DataFrame(data = {'predicted value': tree_predictions, 'actual value':list(int(val) for val in y_test)}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "As you can see, the predicted values differ from the y_values for each row; the accuracy of each row differs. To better understand our model's performance, however, we want to view a few different measures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Measure the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a well known measurement, but for reasons we won't get into, we will use a measure called **F1 Score** instead. \n",
    "<br><br>\n",
    "<sup>\n",
    "For more information, you can read up on why accuracy *alone* is not a great measure of a model:\n",
    "<br>\n",
    "https://tryolabs.com/blog/2013/03/25/why-accuracy-alone-bad-measure-classification-tasks-and-what-we-can-do-about-it/ \n",
    "<sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 Score = 0.45\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=tree_predictions)\n",
    "print(\"Decision Tree F1 Score = {}\".format(round(f1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this decision tree is quite accurate, we can possibly improve accuracy using the random forest model. The random forest model essentially builds multiple decision trees, takes the outputs from all of those trees, and determines the best prediction by taking the average (regression) or the mode (classification) of the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/random-forest.jpg\" width=\"700\" height=\"700\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest is an **ensemble model** i.e., it combines multiple models into one larger model. By combining multiple decision trees, the random forest is able to improve the prediction accuracy. \n",
    "\n",
    "<br> The random forest combines multiple decision trees by using a concept called **bootstrap aggregating**, or **bagging** for short. This method builds multiple (usually 1,000's) decision trees during the *Train the Model* step. When we *Test the Model*, each decision tree predicts the output and the random forest combines all the outputs into a *single* output. It does this by either taking a majority vote (in classification) or by aggregating the values (in regression, which is our case) by use of a mean, median, etc. \n",
    "\n",
    "This is all done behind the scenes within sklearn. The same 3-step process is used (recall that the data was originally split above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we import, instantiate, and then fit\n",
    "<br>\n",
    "Here, n_estimators is the number of decision trees in our random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate \n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 10)\n",
    "\n",
    "# train/fit\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted values</th>\n",
       "      <th>actual value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted values  actual value\n",
       "0                 0             0\n",
       "1                 0             0\n",
       "2                 0             0\n",
       "3                 0             1\n",
       "4                 0             0\n",
       "5                 0             0\n",
       "6                 0             1\n",
       "7                 1             0\n",
       "8                 0             0\n",
       "9                 0             1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's predict and see the predictions next to the actual y values\n",
    "\n",
    "# predict\n",
    "rf_predictions = rf.predict(X_test)\n",
    "\n",
    "# format and print\n",
    "pd.DataFrame(data = {'predicted values':rf_predictions, 'actual value': list(int(val) for val in y_test)}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Measure the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1 Score = 0.52%\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=rf_predictions)\n",
    "print(\"Random Forest F1 Score = {}%\".format(round(f1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown here, our Random Forest \"out of the box\" improved our F1 Score over the Decision Tree's \"out of the box\" F1 Score (0.45). \n",
    "<br>**Ensemble models are known to improve accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we see that simply using Random Forest is better than a single decision tree, there is still room for improvement. These next 2 sections will show you some techniques to both simplify and tune your model in order to improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Over/Under Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we use our trained model on the training set of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Data F1 Score = 0.98\n"
     ]
    }
   ],
   "source": [
    "predictions_training = rf.predict(X_train)\n",
    "\n",
    "f1 = f1_score(y_true=y_train, y_pred=predictions_training)\n",
    "print(\"Random Forest Training Data F1 Score = {}\".format(round(f1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By fitting the model \"out of the box\", we allowed the tree to grow as large as possible (we can see this because there was almost no error when it predicted the y values for the training data... the model predicted almost every y value exactly).This behavior is known as **overfitting**.\n",
    "\n",
    "Overfitting is when the model follows the *\"noise\"* of the **training data** too closely, and therefore won't predict general input data later on. <br>\n",
    "http://www.r2d3.us/visual-intro-to-machine-learning-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/overfitting_underfitting.png\" width=\"700\" height=\"700\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways to combat overfitting by tuning the model. One way to do this is decrease the depth of each tree (either before or after fitting - research *pruning*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create several RF models, each with a different max_depth input. We can see how each of these performs to determine which of the models are overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = list(range(3,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "accuracy_list=[]\n",
    "test_f1_list=[]\n",
    "\n",
    "for depth in max_depths:\n",
    "    ## import - already done\n",
    "\n",
    "    ## instantiate \n",
    "    rf = RandomForestClassifier(max_depth = depth, n_estimators = 1000, random_state = 10)\n",
    "\n",
    "    ## train/fit\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on the training data \n",
    "    predictions_testing = rf.predict(X_test)\n",
    "    \n",
    "    # f1 score for test set \n",
    "    test_f1 = f1_score(y_true=y_test, y_pred=predictions_testing)\n",
    "    test_f1_list.append(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=max_depths, y=test_f1_list)\n",
    "plt.title(\"Performance of Several RF Models with Different Max Depths\")\n",
    "plt.xlabel(\"Depth of Trees in Model\")\n",
    "plt.ylabel(\"F1 Score of Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance (f1 score) of the testing data helps us which models are overfitting. The inflection point at Depth of Tress in Model = 7 shows us that our Random Forest models with max_depth greater than 7 will overfit the data and therefore perform lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a RF with max_depth = 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import - already done\n",
    "\n",
    "## instantiate \n",
    "rf = RandomForestClassifier(max_depth = 7, n_estimators = 1000, random_state = 10)\n",
    "\n",
    "## train/fit\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1 Score = 0.55\n",
      "We improved our F1 Score from 0.52 to 0.55\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=rf_predictions)\n",
    "print(\"Random Forest F1 Score = {}\".format(round(f1, ndigits=2)))\n",
    "print(\"We improved our F1 Score from 0.52 to 0.55\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this process above for all the parameters (hyperparameters) in the Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 1000,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 10,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we will build one model for all combinations of hyperparameters, calculate the model performance, and then return the best one. \n",
    "<br>\n",
    "This process is called a **Grid Search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # build param grid\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # create parameter grid\n",
    "# param_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "\n",
    "# # run (and time) grid search\n",
    "# # instantiate\n",
    "# rf = RandomForestClassifier(random_state=10)\n",
    "# k = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# rf_cv = GridSearchCV(rf, param_grid, cv=k, scoring='f1')\n",
    "\n",
    "# # fit \n",
    "# rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# # save results\n",
    "# pickle.dump(rf_cv, open( \"models/rf_cv_manyparams.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build param grid\n",
    "# # from above\n",
    "# max_depth = list(range(3,15))\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# param_grid = {'n_estimators': n_estimators,\n",
    "#                'max_depth': max_depth}\n",
    "\n",
    "\n",
    "\n",
    "# # run grid search\n",
    "# # instantiate\n",
    "# rf = RandomForestClassifier(random_state=10)\n",
    "# k = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# rf_cv = GridSearchCV(rf, param_grid, cv=k, scoring='f1')\n",
    "\n",
    "# # fit \n",
    "# rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# # save results\n",
    "# pickle.dump(rf_cv, open( \"models/rf_cv.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small or large grid search results?small\n"
     ]
    }
   ],
   "source": [
    "# load results\n",
    "many_params = input(\"small or large grid search results?\")\n",
    "if many_params == 'small':\n",
    "    rf_cv = pickle.load( open( \"models/rf_cv.pickle\", \"rb\" ) )\n",
    "elif many_params == 'large':\n",
    "    rf_cv = pickle.load( open( \"models/rf_cv_manyparams.pickle\", \"rb\" ) )\n",
    "else:\n",
    "    print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for our RF are {'max_depth': 14, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters for our RF are {}\".format(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\tomsharp\\AppData\\Local\\Continuum\\miniconda3\\envs\\dm_ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth param_n_estimators\n",
       "0              14                200\n",
       "1              11                200\n",
       "2              12                400\n",
       "3              10                800\n",
       "4              10               1000\n",
       "5              12                200\n",
       "6              10                600\n",
       "7              11                400\n",
       "8              14                800\n",
       "9              13                800"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the grid\n",
    "scores_df = pd.DataFrame(rf_cv.cv_results_).sort_values(by='rank_test_score')\n",
    "param_keys = [key for key in rf_cv.cv_results_.keys() if 'param_' in key]\n",
    "scores_df = scores_df[param_keys].reset_index(drop=True)\n",
    "scores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a model with the best parameters\n",
    "rf_best = rf_cv.best_estimator_\n",
    "rf_best.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score = 0.5\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "rf_best_predictions = rf_best.predict(X_test)\n",
    "print(\"Best F1 Score = {}\".format(f1_score(y_true = y_test , y_pred = rf_best_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Confusion matrix, without normalization\n",
      "[[44  7]\n",
      " [17 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.79        51\n",
      "           1       0.63      0.41      0.50        29\n",
      "\n",
      "   micro avg       0.70      0.70      0.70        80\n",
      "   macro avg       0.68      0.64      0.64        80\n",
      "weighted avg       0.69      0.70      0.68        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEYCAYAAADGepQzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xm8nOP9//HX+yRBIiSIqD1qLVqxlqpSWykl1L5G1dYfpaqlllqqLW1RX9qqNZbaqrbaKYmlpITYSaxVgsS+hiSf3x/XdZiMc2bmZOace84572ce9yMz99xz359Zzmeu67qv+7oUEZiZ9XYtRQdgZtYMnAzNzHAyNDMDnAzNzAAnQzMzwMnQzAxwMmw4Sf0l/VPSO5L+Xsd+dpZ0SyNjK4qkdSQ93SzHkzRMUkjq21UxdReSXpC0Yb59uKSzO+EYZ0g6qtH7rZd6az9DSTsBBwPLAe8B44FfR8Tdde53V+AA4BsRMa3uQJucpACWjohnio6lPZJeAH4YEbfl+8OA54F+jf6MJI0C/hcRRzZyv12l/L1qwP5G5v19sxH760y9smQo6WDgj8BvgAWAxYA/A1s2YPeLAxN6QyKshUtfncfvbYNFRK9agEHA+8C2FbaZnZQsX8nLH4HZ82PrAf8Dfgq8DkwC9siPHQt8Anyaj7EncAxwUcm+hwEB9M33RwLPkUqnzwM7l6y/u+R53wDuB97J/3+j5LHRwK+Ae/J+bgGGtPPaWuP/eUn8I4DvAhOAN4HDS7ZfA7gXeDtvezowW37szvxaPsivd/uS/R8KvApc2LouP2fJfIxV8v2FgCnAejV8ducDP823F87H/lG+v1Ter8qOdyEwA/gox/jzks9gd+C/+fhH1Pj5z/S55HWRj793/uw/ycf6ZzuvI4B9gYnAW8Cf+LyW1gIcCbyYP58LgEFl3509c9x3lqzbA3gp729fYHXgkfy5nV5y7CWB24E38uv+GzC45PEXgA3z7WPI3938ub9fskwDjsmPHQY8S/ruPQFsldd/BfgYmJ6f83ZePwo4vuSYewHP5M/vWmChWt6rhueGopNTVy/AJvmD7Fthm+OA+4ChwPzAv4Ff5cfWy88/DuhHSiIfAvOUf4Haud/65e0LzAm8CyybH1sQWKH8jw6YN38Rds3P2zHfny8/Pjp/GZcB+uf7J7Tz2lrj/2WOfy9gMnAxMBewQv4CfzlvvyqwZj7uMOBJ4KDyRNDG/k8kJZX+lCSnki//k8AA4GbgDzV+dj8gJxhgp/yaLyt57JqSGEqP9wL5D7zsMzgrx7cSMBX4Sg2f/2efS1vvAWV/6O28jgCuAwaTaiWTgU1KXsczwJeBgcCVwIVlcV9A+u70L1l3BjAHsHH+/K7O8S9MSqrr5n0sBWyUP5v5SQn1j229V5R9d0u2GZ5jXjnf35b0o9ZC+kH8AFiwwvv12XsErE9KyqvkmE4D7qzlvWr00huryfMBU6JyNXZn4LiIeD0iJpNKfLuWPP5pfvzTiLiB9Ku37CzGMwNYUVL/iJgUEY+3sc1mwMSIuDAipkXEJcBTwPdKtjkvIiZExEfA5aQvbHs+JbWPfgpcCgwBTo2I9/LxHwe+BhAR4yLivnzcF4C/AuvW8JqOjoipOZ6ZRMRZpF/6saQfgCOq7K/VGGAdSS3At4DfAWvnx9bNj3fEsRHxUUQ8DDxMSopQ/fNvhBMi4u2I+C9wB59/XjsDJ0fEcxHxPvALYIeyKvExEfFB2Xv7q4j4OCJuISWjS3L8LwN3ASsDRMQzEXFr/mwmAydT/fP8jKT5SYn2gIh4KO/z7xHxSkTMiIjLSJ/tGjXucmfg3Ih4MCKm5te7Vm7XbdXee9VQvTEZvgEMqdLeshCpmtLqxbzus32UJdMPSb/iHRIRH5B+SfcFJkm6XtJyNcTTGtPCJfdf7UA8b0TE9Hy79Q/qtZLHP2p9vqRlJF0n6VVJ75LaWYdU2DfA5Ij4uMo2ZwErAqflP4KqIuJZ0g/PcGAdUonhFUnLMmvJsL33rNrn3wgdOXZfUtt2q5fa2F/559fe5zlU0qWSXs6f50VU/zzJz+0HXAFcHBGXlqzfTdJ4SW9Lepv0uda0T8peb/4BeINZ/27Pst6YDO8lVSNGVNjmFdKJkFaL5XWz4gNSdbDVl0ofjIibI2IjUgnpKVKSqBZPa0wvz2JMHfEXUlxLR8TcwOGkdrlKKnZRkDSQ1A53DnCMpHk7EM8YYBtSu+XL+f5uwDykHgEdjqcNlT7/mT5PSTN9nrNwrFqOPY2Zk1s9x/htfv7X8ue5C9U/z1ankdoFPztTLmlx0nd2f1KzzWDgsZJ9Vot1ptcraU5S7a0rvtsz6XXJMCLeIbWX/UnSCEkDJPWTtKmk3+XNLgGOlDS/pCF5+4tm8ZDjgW9JWkzSIFI1AABJC0jaIn8BppJKPdPb2McNwDKSdpLUV9L2wPKkklFnm4vUrvl+LrXuV/b4a6T2rY44FRgXET8Erie1dwEg6RhJoys8dwzpD+/OfH80qSvT3SWl3XIdjbHS5/8wsIKk4ZLmILWr1XOsto79E0lL5B+N35DaRRvVO2Eu8skMSQsDP6vlSZL2IZW+d4qIGSUPzUlKeJPzdnuQSoatXgMWkTRbO7u+GNgjv5+zk17v2Nwk06V6XTIEiIiTSX0MjyR9iC+R/sCuzpscDzxAOhv3KPBgXjcrx7oVuCzvaxwzJ7AW0lnpV0hn0tYFftTGPt4ANs/bvkE6I7p5REyZlZg66BDSyYr3SCWAy8oePwY4P1eRtqu2M0lbkk5i7ZtXHQysImnnfH9R0lnx9owh/UG3JsO7SSW1O9t9RioNHZljPKRajFT4/CNiAukEy22ktrHyfqnnAMvnY11Nx51LOgN+J6l3wcekZN8ox5JOVrxD+iG6ssbn7UhK8q9Iej8vh0fEE8BJpBrXa8BXmfnzu53UBv2qpC98XyPiX8BRwD9IvRWWBHaYlRdWr17b6dqak6TxwAb5B8CsyzgZmpnRS6vJZmblnAzNzHAyNDMDUmdO62Lq2z8021xFh9FjrfyVxYoOoUd78cUXmDJlSq19EyvqM/fiEdO+cJHSTOKjyTdHxCaNOF4lToYF0GxzMfuyVXuh2Cy6Z+zpRYfQo6399dUatq+Y9lHVv4WPx/+p1qtZ6uJkaGbFkaClT9FRAE6GZlY0NcepCydDMyuQS4ZmZokaci6mbk6GZlYctxmamWVuMzQzc8nQzCwNAes2QzMzXE02MwNBH1eTzay3Ey4Zmpn5BIqZWSufQDGzXq+JOl03R2XdzHovtVReatmF1EfSQ5Kuy/eXkDRW0kRJl1WYqvQzToZmVqBcMqy01OZA4MmS+ycCp0TE0sBbwJ7VduBkaGbFkiovVZ+uRYDNgLPzfQHrA1fkTc4HRlTbj9sMzaw4tXWtGSLpgZL7Z0bEmSX3/wj8HGidS2M+4O2ImJbv/w9YuNpBnAzNrEA1nUCZEhFtzjUgaXPg9YgYJ2m9z3f6BVUniHcyNLNi1dfpem1gC0nfBeYA5iaVFAdL6ptLh4sAr1TbkdsMzaw4qu8ESkT8IiIWiYhhwA7A7RGxM3AHsE3ebHfgmmqhOBmaWbHqPIHSjkOBgyU9Q2pDPKfaE1xNNrPCCGhpaUyZLCJGA6Pz7eeANTryfCdDMyuOaPt0RwGcDM2sQGpYybBeToZmVih5oAYz6/UEanEyNLNeTsglQzMzcDXZzAxoXNeaejkZmllx3LXGzCy1GbpkaGaG2wzNzNy1xsyslUuGZtbruc3QzKxVcxQMnQzNrEBqnmpyc5RPram0tIh7LzmUf5y670zrTz50Wybfc1JBUfU8E55+mq+vOvyzZei8c3PaqX8sOqwu19LSUnGpRtIckv4j6WFJj0s6Nq8fJel5SePzMrxiHA16PXWTNFLSQnXu4/0Obr+vpN3aOr6kgyQN6OD+1mudxLo723+nb/P086/NtG6V5Rdj0MD+BUXUMy2z7LKMHTeesePG8+//jGPAgAFsMWKrosPqeqqyVDcVWD8iVgKGA5tIWjM/9rOIGJ6X8ZV20jTJEBgJ1JUMOyoizoiIC9o5/kFAh5JhT7Dw0MFs8s0VOO+qf3+2rqVF/OagERxx6tUFRtaz3XH7v1jiy0uy+OKLFx1Kl5JUd8kwktaCUL+8VJ0Nr1ynJENJwyQ9KemsXGy9RVL//NhwSfdJekTSVZLmkbQNsBrwt1yc7V+2v70k3Z+Lwf9oLbFJWkLSvfmxX5Vsv56kMZIulzRB0gmSds5F6UclLZm3O0bSIW0c/0BSYrxD0h15243zsR6U9HdJA/P6TSQ9JeluYOvOeD+70u9/9n2OOPVqZsz4/Lu03/brcv2YR3l1yrsFRtaz/f2yS9lu+x2LDqMQkiou5HmTS5a929hHH0njgdeBWyNibH7o1znXnCJp9kpxdGbJcGngTxGxAvA28P28/gLg0Ij4GvAocHREXAE8AOyci7Mfle3ryohYPReDnwT2zOtPBf4SEasDr5Y9ZyXgQOCrwK7AMhGxBnA2cEDphm0c/1TS1ILfjohvSxoCHAlsGBGr5G0PljQHcBbwPWAd4Euz9lY1h03XWZHX33yPh5586bN1C84/iK03Wpk/XzqmwMh6tk8++YTrr7uWrbfZtuhQCqEWVVzI8yaXLGeW7yMipkfEcNK0oGtIWhH4BbAcsDowL2mSqHZ15tnk50vq6OOAYZIGAYMjovUv63zg7zXsa0VJxwODgYHAzXn92nyeZC8ETix5zv0RMQlA0rPALXn9o8C3O/ha1gSWB+7Jv1SzAfeS3ujnI2JiPs5FwBd+tfJje3/2WL+BHTx811hr+JfZfN2vssk3V2D22fox95xzMO6KI5j6yTQev/ZoAAbM0Y/HrjmaFbc8tuBoe46bb7qR4SuvwgILLFB0KIVo5NnkiHhb0mhgk4j4Q149VdJ5wCGVntuZyXBqye3pQD2t76OAERHxsKSRwHolj7XXNlB6/Bkl92fQ8dctUtF7pnpMPjtVU9tE/jU7E6BlwNAOt2d0hV+edi2/PO1aANZZdWkO2m0Dvn/gGTNtM/mek5wIG+zyyy7pxVXk1CZd3z40P/BpToT9gQ2BEyUtGBGTlLLtCOCxSvvp0hMoEfEO8JakdfKqXYHWUuJ7wFztPHUuYJKkfsDOJevvIU0cTdn6WVF+/NL79wFrS1oKQNIAScsATwFLtLZBAr3zG22z7MMPP+T2225ly626fXPzLKrcXlhjqXFBUvv+I8D9pILLdaRzAI+SaoNDgOMr7aSITte7A2fkkyDPAXvk9aPy+o+AtcraDY8CxgIvkl5Ya5I6ELg4n/D4R51xzXR8UinuRkmTcrvhSOCSkkbYIyNiQq7+Xi9pCnA3sGKdcTSFu8ZN5K5xE7+wfv61f1pAND3XgAEDePm1N4oOo1D11pIj4hFg5TbWr9+hOCKassbWo7UMGBqzL7td0WH0WG/df3rRIfRoa399NcaNe6AhDX1zLLhMDNv9tIrbPH3iJuMiYrVGHK8SX45nZoUR9bcZNoqToZkVysnQzEz1txk2ipOhmRXG4xmamWUuGZqZNaDTdaM4GZpZYUTzDO7qZGhmhXLJ0MwMtxmamTXVHChOhmZWmNS1xsnQzMzVZDMzd60xM6O5utY0x3UwZtZrtbSo4lKN2p83eQlJYyVNlHSZpNkqxtGg12NmNksaMNJ1e/MmnwicEhFLA2/x+URybWo3GUqau9JS8ys1M2uHVLlUWEvJsMK8yesDV+T155PmQWlXpTbDx/MOS6NpvR/AYlWjNDOroobC3xBJD5TcP7N8ulBJfUizcC4F/Al4Fng7IqblTf4HLFzpIO0mw4hYtGqIZmZ1aqmeDadUG/Y/IqYDwyUNBq4CvtLWZhXjqBYFgKQdJB2eby8iadVanmdmVknrVKH1VJNLRcTbwGjSXOeDJbUW+BYBXqn03KrJUNLppEnXd82rPgTOaP8ZZma1a1HlpRpJ8+cSISXzJj8J3AFskzfbHbim0n5q6Wf4jYhYRdJDABHxZrVT1GZmtWpAp+sFgfNzu2ELcHlEXCfpCeBSSccDDwHnVNpJLcnwU0kt5Pq2pPmAGXWFbmZG7nRNfcmwwrzJzwFr1LqfWpLhn0gTtM+fOzNuBxxb6wHMzNol0ae7XI4XERdIGkeqhwNsGxGPdW5YZtZbNMnVeDVfm9wH+JRUVfZVK2bWEIKmKRnWcjb5COASYCHS6emLJf2iswMzs96hAZfjNUQtJcNdgFUj4kMASb8m9fT+bWcGZmY9n9Q8JcNakuGLZdv1BZ7rnHDMrLdpjlRYIRlKOoXURvgh8Likm/P9jYG7uyY8M+vpmmU8w0olw9Yzxo8D15esv6/zwjGz3kTdoWtNRFTsrW1m1ghNUjCs3mYoaUng18DywByt6yNimU6My8x6gW7VtQYYBZxHintT4HLg0k6Mycx6kWbpWlNLMhwQETcDRMSzEXEkaRQbM7O6SNBHqrh0lVq61kxVSs/PStoXeBkY2rlhmVlv0W3aDIGfAAOBH5PaDgcBP+jMoMys9+g28yZHxNh88z0+H+DVzKxuQrUM+98lKnW6vooKcwZExNadElEvsPSXF+Kvl3oUtM7y8psfFR1Cj/bJ9AYOZ6r6q8mSFgUuAL5EGmv1zIg4VdIxwF7A5Lzp4RFxQ3v7qVQyPL2+EM3MqmvASZJpwE8j4kFJcwHjJN2aHzslIv5Qy04qdbr+V70RmplVIuq/HC8iJgGT8u33JD1JlWlB2+KxCc2sUH1bKi/keZNLlr3b25ekYaQpAFrPdewv6RFJ50qap1IcToZmVhippk7XUyJitZLlzLb3pYGkKUoOioh3gb8ASwLDSSXHkyrFUutI10iaPSKm1rq9mVkt+jSgSCapHykR/i0irgSIiNdKHj8LuK7SPmoZ6XoNSY8CE/P9lSSdVk/gZmaQ2gxbpIpL1X2k4uM5wJMRcXLJ+gVLNtuKz0fialMtJcP/AzYHrgaIiIcl+XI8M2uIPvV3M1yb1Af6UUnj87rDgR0lDSd1EXwB2KfSTmpJhi0R8WLZGZ/pHQ7XzKyMaiz9VRIRd9P2gNnt9ilsSy3J8CVJawCRZ6w/AJjQkYOYmbWnEW2GjVBLMtyPVFVeDHgNuC2vMzOrS2ubYTOo5drk14EduiAWM+uFmiQX1jTS9Vm0cY1yRLTb8dHMrCZqyOV4DVFLNfm2kttzkE5Rv9Q54ZhZb5KqyUVHkdRSTb6s9L6kC4Fb29nczKxDmmUOlJqvQCmxBLB4owMxs96nW5UMJb3F522GLcCbwGGdGZSZ9RLqJiXDfJnLSqR5TwBmRES7A76amXVEM5UMK3Z3zInvqoiYnhcnQjNroMoz43XlmeZa+n7/R9IqnR6JmfU6aXDXyktXqTQHSt+ImAZ8E9hL0rPAB6T4IyKcIM2sPmqeanKlNsP/AKsAI7ooFjPrZUT3OIEigIh4totiMbNeqDtcmzy/pIPbe7B0EEUzs1khGjKeYUNUOoHSBxgIzNXOYmZWn9rmQKm8C2lRSXdIelLS45IOzOvnlXSrpIn5/4oTQlUqGU6KiOM69srMzGqXSoadNm/ySOBfEXGCpMNIF4sc2t5OKpUMm6TwamY9maos1UTEpIh4MN9+D2idN3lL4Py82flUORlcqWS4QQ1xmJnVQbRUP5s8RNIDJffPrDBd6DA+nzd5gTzBPBExSdLQSgdpNxlGxJvVIjQzq4eo6cqPKRGxWtV9lc2bXEt7Y6kmmX3AzHqrek+g5H18Yd5k4LXW6ULz/69X2oeToZkVR503bzJwLbB7vr07cE2l/czKeIZmZg1RYzW5mvbmTT4BuFzSnsB/gW0r7cTJ0MwK1YnzJkMHTgQ7GZpZoZrkajwnQzMrToM6XTeEk6GZFUioSa7vcDI0s8K4ZGhmBnmghqKDSJwMzaxQ3WE8QzOzTtVMs+M5GZpZoXwCxZrSiYf/mPtG38Lg+YZw3j/vBuDYn+zJS8+n2R/ef/cdBs49iLOvHl1glN3XYQfuw+233sR8Q+bnxjvTQCwnHHs4t99yA/36zcZiw5bgxFP/ytyDBhccaddplmpyj7k2WdJISad38Dk3SBqclx+VrB8maadZiGGUpG06+rxmsslWO3DiWZfNtO7oU87h7KtHc/bVo/nWxpuzzkabFRRd97f1Drty7qVXz7Ru7XXX54YxD3D96P+wxJJLc8b//aGg6LpeazW50tJVekwynBUR8d2IeBsYDPyo5KFhQIeTYU+w0urfYO5BbY+OHhGMvukaNths6y6OqudYY61vMnjwvDOtW2e9DenbN1XShq+6Oq++8nIRoRWjyiANXVlq7DbJUNLVksblOQ72zuv2kDRB0hjSxdqt246S9Jc8L8JzktaVdG6eI2FUyXYvSBpCuqB7SUnjJf0+318n3/+JpD6Sfi/pfkmPSNonP1+STpf0hKTrgYqDR3Z3jzxwL/PMNz+LDFuy6FB6rL9ffAHf2mDjosPoUvWOdN0o3anN8AcR8aak/sD9OfkcC6wKvAPcATxUsv08wPrAFsA/Scnyh/m5wyNifMm2hwErRsRwAEnrAYdExOb5/t7AOxGxuqTZgXsk3UIaUXdZ4KvAAsATwLltBZ/3sTfAAgstUu97UYjbr7/SpcJO9OdTTqRv375s+f0dig6lyzRTp+tuUzIEfizpYeA+YFHSkD2jI2JyRHwCXFa2/T8jIoBHgdci4tGImAE8TqoGd8TGwG55eKCxwHzA0sC3gEsiYnpEvALc3t4OIuLMiFgtIlYbNM98HTx88aZPm8Zdt17Pt7+7VdGh9EhXXnYRt996Iyf/+byaBzTtMZqkaNgtSoa5pLYhsFZEfChpNPAU8JUKT5ua/59Rcrv1fkdft4ADIuLmsri+C0QH99Utjbt3DIsusRTzf2mhokPpccbcfgt/Pf1kLr7qZvoPGFB0OF3OZ5M7ZhDwVk6EywFrAv2B9STNl4f8rjhwYxXvMfNc0OX3bwb2y8dB0jKS5gTuBHbIbYoLAt+uI4am8KuD9+L/7bgJLz3/DNuu+1Wuv+IiAG6//io22NxV5HodtM/ubLvZejz/7ATWHr4Ul/9tFMf+4mA+eP89Rm63Od9b/+sc9bMDig6zS9VbMMznA16X9FjJumMkvZzb/cfngktF3aJkCNwE7CvpEeBpUlV5EnAMcG++/SBp4vsOi4g3JN2T38wbSaPkTsvV8lHAqaSq9YN5iPHJpGkHryK1Sz4KTADGzNrLax5HnXxWm+sPO6FDvZasHX/86/lfWLfdziO7PpBmUn/BcBRwOnBB2fpTIqLmfkrdIhlGxFRg0zYeGg2c18b2I0tuvwCs2M5jw0pul3elKR8h9/C8lNu/nbDNrAqpISNd35mnCK1Ld6kmm1kPVUM1eYikB0qWvWvc9f65K9y5ktruPFvCydDMClR5mtB8Zn1Ka0+MvLQ5gXyZvwBLAsNJzWgnVXuCk6GZFUqqvMyKiHgtd3mbAZwFrFHtOU6GZlYY0TnJsHXy+Gwr4LH2tm3VLU6gmFnPVe8QXpIuAdYjtS3+Dzia1O1uOKkf8AvAPtX242RoZoWqd2SaiNixjdXndHQ/ToZmVpyuHo2hAidDMytMGs+wObKhk6GZFao5UqGToZkVrUmyoZOhmRXK1WQzM5qmYOhkaGbFSZ2umyMdOhmaWXHquMqk0ZwMzaxQToZmZqjuy/EaxcnQzArTOol8M3AyNLNiORmamdU/ak2jOBmaWaFcTTYza6KuNR7p2swK09rpusocKJX30fa8yfNKulXSxPy/J4Qys+ZW7yTypHmTNylbdxjwr4hYGvhXvl+Rk6GZFapFqrhUExF3Am+Wrd4SOD/fPh8YUW0/bjM0s2JVz3dDJD1Qcv/MGqYLXSAiJgFExCRJQ6sdxMnQzAoj1XQ2eUpErNbZsbiabGaFUpV/s+i11ulC8/+vV3uCk6GZFaoz5k0GrgV2z7d3B66p9gQnQzMrVL3JMM+bfC+wrKT/SdoTOAHYSNJEYKN8vyK3GZpZgeoftaadeZMBNujIfpwMzawwqdN10VEkToZmVignQzMzeXY8M7OOXHLX6ZwMzaxQnh3PzAy3GZqZAU6GZmZA8wz7r4goOoZeR9Jk4MWi4+iAIcCUooPowbrb+7t4RMzfiB1Juon0+iuZEhHl4xU2nJOhVSXpga4YNaS38vvbHHxtspkZToZmZoCTodWm2qjCVh+/v03AbYZmZrhkaGYGOBmamQFOhlaBpK9JWqDoOHoySQOLjsESJ0Nrk6QBwE7AGZIa0sHWZiZpBeBQSSsVHYs5GVobJCkiPgROAV4Afi9pvmKj6pHeBxYFvitpxaKD6e2cDO0L4vMuBpsBcwIrAye5ytwYymNWRcSLwL+B7wAHS1qm0MB6OSdDa5OkTYGfA78GjgJeISVElxDr1PpjI2k/YFtgFLAisEuuOlsBnAwN+Ly0os9H2pwduCWXXm4ELgEWJLUhVruw3ipQMhDYGPhNRIwCtgeWBA6UtHyR8fVWTobW2kbYWjWePf//MLCxpC0j4tOIeBR4ApgMzFZEnN1ZyY8MkbwPPAV8S9LgiHgeOBkYAXxH0uzt7Mo6iccztNJq296kP86JwDjgp8BPJS0OvAMsD+wYEa8XFmw3VPpjI2lDYBBp0vOHgLWADST9M6+/DbgsIqYWFW9v5WRoAEj6IakrzcHAH4ABpLbCd4H9gKnAwU6EHVeSCA8EtgPuAY4G9iKN5bcxcAAwF7BLRLxSUKi9mpOhtZoH2JX0hzkdOCKvfzAidiqrSlsHSVoaWC8i1s4nTqZExFhgbG4/XBx4IyJeLTTQXsxthr2QpAVa+7VJ2j6fIZ5BqrptGxEbRcQ0YE9gN0l9nAg7RtI8kvrl24sDk4CHJI0itQtunB/bDegTEY87ERbLJcPeaSBwlqRngOWAO4CLgVWBlwEk7Q7sD2wXEdOLCrQ7yklwTeCbkt4EvgycBCyUb+8UEdMk7QIcAtxOapO1AnkIr15EUt9c4kPS/sDvgEMj4jRJ/YHhwP8DhgL9gAMi4rHCAu7Gcmn7StJJp/Ui4nFJawE/A94G+pDe7539HjcHJ8NeQtIgYF3gJmBfYDDwKCkhHhcRF+btFBEhac5UGIsAAAAKK0lEQVSI+KCwgLshSUOBwRExQdJ3SO/zG8AnwC8jYkquMi8KzAc8HBEvFBawzcTV5F5A0nwR8YakdUlnMQVsExHPSfoI+LOkd4EvkbrW7A58WGDI3dVQ4BRJL5H6Yu5Dapf/BfB7YA9gAWBGRFxTWJTWJp9A6eEkLQmMzHcvIiXCp4HXJM0RETeRqsZ7Ad8HfhcR03zCpHaS1pW0Qq7uTgC2AUbnbkhvAn8BPpQ0DjiLdDLFmoyryT2cpHlJZ4oXBlYB/gn8llQr+HVEvCBpbuADYEBEvFdYsN2UpB1IAy5MAdYgnZTah9T8cFXeZj5gNeDZiHimqFitfU6GPVTZVQ9zAIeTOvieB4wHzgA+Bt4iXRe7ekS8XVC43VLZe7w0MAYYERH/kbQjqXp8AOlk1OoR8dviorVqnAx7oLI/0tb2wjlJDfrDSIMujCV1nVkMGJWvPbYatdUJXdJPSM0NI3NC3BY4FvgI2DUiniggVKuRk2EPJumnwA7AfcDNpDPJPyFVma+PiFsltUTEjALD7NZyFXk54G8RMVHSXqTuM7tGxFhJiwKfRMRrhQZqVfkESg9SOjJK7sKxAvBjUnvW3sAWpNGr3yINDjCnE2HHlL3H25MGs1gYOFnSiIg4CzgRuEHS6hHxkhNh9+CuNT1EWdV4C2B14NWIuFfSw6SuMnuQhug6HhjkfoQdU/YeDyVdybNz7lf4I2DrvMk5kj4l/ehYN+Fk2M2Vt13latshpOGh1pH0j4gYJ+kmUiLcGrguIt4sJuLuqbQ5IY8+sx+pZrU28IOI+LOkGcAekqZHxAUFhmuzwNXk7m8RSMNESdoAOAjYPCL2Il1vfEyurk0FrgF+6O4zHSOpX0kiXBv4OrA+6Sz8MpKOB4iIM0hdlx4sKlabdU6G3VQeOn5u4DFJB+fV/UjtVwcCRMRxpLPGJ0laJSKm5hGWrUZKkzT9WtKXlKZMPZp0KePUiHiI1Bb7TUmnAETEOR6PsHtyMuy+WiLiXeAbwOGSdslXk+wBLNeaICPieOA60nD91gH5ZMlQ0qV1+5NGlvkdqX/mxrnb0hOkvoRfkTR/6QkW617cZthNlQyrNRC4AThb0mwRcW7+e9xX0oCIOD4ifldYoN1USVvs3ZKWI03neRhwAik57pw3uyUiHpW0RUR8UmDIVicnw25M0khSG+EewF2k6nCfiDhL0mzATvlyvLd8rXHHlJw1PgjYFHiJNEbh0cBxebP9gE/zSSonwm7OybB7GwicnduuHpL0FHBdLtScLWl0RHj0mVmUf0g2I43+/XYe9WdbUqfqE4FpwOPuq9kzuM2wm2inLWoaqSM1ABFxF6nKfKykQU6EHVPWoXoOUhvh3KSESESMIY0Evh3w84i4JSJeLiJWazxfjtcNlHX23Z40SvLzuUP1DXmzH5MGb10aODk8i12HlL3H+5NGqJ5IGolmLdLli9fn93910lBnfo97ECfDbiQPBDCCVPrbCLg0V4dPA+YgXX63t4eRn3X5SpLtSSdIHiBd130RacCF+4F1gO9GxNOFBWmdwm2G3YSkVYA1I2JdSUeRkt86uUPwAXkbD9Vfh9xvcxXS4BbbkYY6ey/fPo40hP8vI+K/hQVpncYlw24iDw46J2kGuwNJ7VgHATsCF0bEiW0NK2UdI2l20ig0f4yIb0tqIfXRPIVUNfZZ4x7KJ1CaUGtDfmmDfkS8kUskQ4FrcgnwddLlXxfkbZwI65QvW/wQ6Cvpq8AmwI3ABU6EPZuryU1G0lzAVNKMakOB8uGfngVuUprbZFPgOxHhOTUa67+kq3ZOJk3gtJ2rxj2fq8lNRFJfUsP9dNJ0khuRrnyYlgdiaJ3Gc01gSeA/ETGxuIh7LqWJ4L9EmsnO3Wd6ASfDJiNpEdJcGrMBm0XEI2WPu13QrBO4zbAJlLYRRsT/gDNJ1eF1JA0p37yr4zPrDVwyLFhZZ9/1gbeB94FXgctJ8++eIGk74KnykqKZNYZPoBSsJBH+GNiNNDDossC5wC7ARUrTUH4P+FZRcZr1dC4ZNgFJCwFXAN+PiEmSliclw8OAx0lXljznM5pmncdthgVoZ9CFj4EPAPKAoRcDq0bE5IgY7URo1rmcDLtYWRvh0gB5mPgJwD9KNh0ILJmH9/dJE7NO5jbDLtTGyCg/lnQf6QqHg0mDsz5EGohhS2Abd6Mx6xpOhl2obF7jr5GuIFkfWAOYOyL2k7Q5aYiuUe5QbdZ1fAKli0laGLgXuC0ifpCH59+aNGbeC8BfPSirWddzm2EXy5d2HQRsImmHfPH/5aQuNUNJE72bWRdzNbkAEXGlpKnAbyUREZdKuhCY0xO8mxXDybAgeQj5GcCZkqZFxBWkgUTNrABuMyyYpI2AZyPiuaJjMevNnAzNzPAJFDMzwMnQzAxwMjQzA5wMzcwAJ0MzM8DJ0BpA0nRJ4yU9JunvkgbUsa/1JF2Xb28h6bAK2w6W9KNZOMYxkg6pdX3ZNqMkbdOBYw2T9FhHY7Su52RojfBRRAyPiBVJU5zuW/pgHoWsw9+1iLg2Ik6osMlgoMPJ0KwtTobWaHcBS+US0ZOS/ky67npRSRtLulfSg7kEORBA0iaSnpJ0N2nQCvL6kZJOz7cXkHSVpIfz8g3gBNKYj+Ml/T5v9zNJ90t6RNKxJfs6QtLTkm4jTatQkaS98n4elvSPstLuhpLukjQhjzKEpD6Sfl9y7H3qfSOtazkZWsPkeZ83BR7Nq5YFLoiIlUmjeB8JbBgRqwAPAAdLmgM4izTHyzqkuYrb8n/AmIhYCViFNB3CYaSrd4ZHxM8kbQwsTRoSbTiwqqRvSVoV2AFYmZRsV6/h5VwZEavn4z0J7Fny2DBgXWAz4Iz8GvYE3omI1fP+95K0RA3HsSbha5OtEfpLGp9v3wWcAywEvBgR9+X1awLLA/fkgbtnIw1lthzwfOvYjZIuAvZu4xjrkybMIiKmA+9Imqdsm43z8lC+P5CUHOcCrmodGk3StTW8phUlHU+qig8Ebi557PKImAFMlPRcfg0bA18raU8clI89oYZjWRNwMrRG+CgihpeuyAnvg9JVwK0RsWPZdsOBRl0TKuC3EfHXsmMcNAvHGAWMiIiHJY0E1it5rHxfkY99QESUJk0kDevgca0griZbV7kPWFvSUgCSBkhaBngKWELSknm7Hdt5/r+A/fJz+0iamzTKz1wl29wM/KCkLXJhSUOBO4GtJPWXNBepSl7NXMAkSf2Ancse21ZSS475y8DT+dj75e2RtIykOWs4jjUJlwytS0TE5FzCukRS6wC2R0bEBEl7A9dLmgLcDazYxi4OJA13ticwHdgvIu6VdE/uunJjbjf8CnBvLpm+D+wSEQ9KugwYD7xIqspXcxQwNm//KDMn3aeBMcACwL4R8bGks0ltiQ8qHXwyMKK2d8eagUetMTPD1WQzM8DJ0MwMcDI0MwOcDM3MACdDMzPAydDMDHAyNDMD4P8Dgl0VVnfBFfsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plot_confusion_matrix(y_true = y_test , y_pred = rf_best_predictions, classes=['not admitted','admitted'])\n",
    "report = classification_report(y_true = y_test , y_pred = rf_best_predictions)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: undergrad_gpa            Importance: 0.53\n",
      "Variable: gre_score                Importance: 0.36\n",
      "Variable: undergrad_school_rank     Importance: 0.12\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf_best.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_names, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20}     Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the candidate's Undergraduate GPA makes up about 50% of the decision on whether they will be admitted or not, and Undergraduate School Rank is the least important factor in making an admission decision. <br>\n",
    "Does this make sense? It is always improtant to look at your model output and determine if it logically matches the context of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Predicting Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa = float(input(\"Undergrad GPA (0.0 - 4.0)\"))\n",
    "gre = int(input(\"GRE Score (Max 800)\"))\n",
    "rank = int(input(\"Undergrad School Rank (1 - 4)\"))\n",
    "\n",
    "\n",
    "inp = np.array([gre, gpa, rank]).reshape(1,3)\n",
    "prediction = rf_best.predict(inp)\n",
    "\n",
    "print('\\n')\n",
    "if prediction == 0:\n",
    "    print(\"Not Admitted\")\n",
    "elif prediction == 1:\n",
    "    print('Admitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "## Resources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introductory Topics ###\n",
    "\n",
    "*Learning Data Science* <br>\n",
    "https://towardsdatascience.com/how-to-learn-data-science-if-youre-broke-7ecc408b53c7 <br>\n",
    "https://www.class-central.com/subject/data-science <br>\n",
    "\n",
    "*Jupyter* <br>\n",
    "https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html\n",
    "\n",
    "*Pandas* <br>\n",
    "https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n",
    "\n",
    "\n",
    "### Deep Dive Topics ###\n",
    "\n",
    "*Information Gain and Entropy* <br>\n",
    "https://www.saedsayad.com/decision_tree.htm <br>\n",
    "\n",
    "*Ensemble Models - The Power of Crowds and Aggregated Predictions* <br>\n",
    "https://www.npr.org/sections/money/2015/08/07/429720443/17-205-people-guessed-the-weight-of-a-cow-heres-how-they-did <br>\n",
    "\n",
    "\n",
    "*Accuracy, Precision, Recall, F1* <br>\n",
    "https://towardsdatascience.com/precision-vs-recall-386cf9f89488 <br>\n",
    "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c <br>\n",
    "\n",
    "*Random Forest - Feature Information* <br>\n",
    "http://explained.ai/rf-importance/index.html <br>\n",
    "http://www.scikit-yb.org/en/latest/api/features/importances.html <br>\n",
    "\n",
    "*Grid Search* <br>\n",
    "https://www.quora.com/Machine-Learning-How-does-grid-search-work <br>\n",
    "\n",
    "\n",
    "### General ####\n",
    "\n",
    "*Good Reads* <br>\n",
    "https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 <br>\n",
    "https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12 <br>\n",
    "https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d <br>\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0 <br>\n",
    "https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained <br>\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
