{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Predicting Boston Housing Prices using Random Forest*\n",
    "#### Authors: Tom Sharp, Troy Sattgast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Agenda ##\n",
    "Part 1: Data Import, Exploration, and Cleaning <br>\n",
    "Part 2: Decision Tree - The Building Block of Random Forest <br>\n",
    "Part 3: Random Forest <br>\n",
    "Part 4: Forest Simplification <br>\n",
    "Part 5: Tuning the Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os library, the pandas library (aliased as pd), and the numpy library (aliased as np)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsattgast\\Documents\\PyScripts\\random_forest\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsattgast\\Documents\\PyScripts\\random_forest\n",
      "C:\\Users\\tsattgast\\Documents\\PyScripts\\random_forest\\data\\Boston Housing Prices.csv\n",
      "C:\\Users\\tsattgast\\Documents\\PyScripts\\random_forest\\data\\boston_data_dict.csv\n",
      "C:\\Users\\tsattgast\\Documents\\PyScripts\\random_forest\\images\n"
     ]
    }
   ],
   "source": [
    "# Store the paths to frequently used files\n",
    "\n",
    "parent_path = os.getcwd()\n",
    "data_path = os.path.join(parent_path,  'data', 'Boston Housing Prices.csv')\n",
    "data_dict_path = os.path.join(parent_path, 'data', 'boston_data_dict.csv')\n",
    "image_path = os.path.join(parent_path, 'images')\n",
    "\n",
    "\n",
    "print(parent_path)\n",
    "print(data_path)\n",
    "print(data_dict_path)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Import, Exploration, and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During any analysis, it is always important to first examine your data. This involves looking at the data itself, the column names, and some summary statistics about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data using the pandas package. The data is stored in what is called a dataframe (similar to a spreadsheet)\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rows, num of columns =  (506, 17)\n"
     ]
    }
   ],
   "source": [
    "# Examine number of rows and columns \n",
    "\n",
    "print(\"num of rows, num of columns = \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         town  tract  longitude   latitude    crime  residential  industrial  \\\n",
      "0      Nahant   2011 -70.955002  42.255001  0.00632         18.0        2.31   \n",
      "1  Swampscott   2021 -70.949997  42.287498  0.02731          0.0        7.07   \n",
      "2  Swampscott   2022 -70.935997  42.283001  0.02729          0.0        7.07   \n",
      "\n",
      "  river    nox  rooms      older  distance  highway  tax    ptratio  lstat  \\\n",
      "0    no  0.538  6.575  65.199997    4.0900        1  296  15.300000   4.98   \n",
      "1    no  0.469  6.421  78.900002    4.9671        2  242  17.799999   9.14   \n",
      "2    no  0.469  7.185  61.099998    4.9671        2  242  17.799999   4.03   \n",
      "\n",
      "       cmedv  \n",
      "0  24.000000  \n",
      "1  21.600000  \n",
      "2  34.700001  \n"
     ]
    }
   ],
   "source": [
    "# That's a lot of rows. Let's just look at the first three columns of the data, instead of all of them\n",
    "\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['town', 'tract', 'longitude', 'latitude', 'crime', 'residential', 'industrial', 'river', 'nox', 'rooms', 'older', 'distance', 'highway', 'tax', 'ptratio', 'lstat', 'cmedv']\n"
     ]
    }
   ],
   "source": [
    "# We can list all the column names by calling the \"columns\" attribute of \"data\" \n",
    "# Def: Attribute - describes the data (an adjective)\n",
    "\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tract   longitude    latitude       crime  residential  \\\n",
      "count   506.000000  506.000000  506.000000  506.000000   506.000000   \n",
      "mean   2700.355731  -71.056389   42.216440    3.613524    11.363636   \n",
      "std    1380.036830    0.075405    0.061777    8.601545    23.322453   \n",
      "min       1.000000  -71.289497   42.029999    0.006320     0.000000   \n",
      "25%    1303.250000  -71.093226   42.180774    0.082045     0.000000   \n",
      "50%    3393.500000  -71.052902   42.218100    0.256510     0.000000   \n",
      "75%    3739.750000  -71.019625   42.252249    3.677083    12.500000   \n",
      "max    5082.000000  -70.809998   42.381000   88.976196   100.000000   \n",
      "\n",
      "       industrial         nox       rooms       older    distance     highway  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    11.136779    0.554695    6.284634   68.574901    3.795043    9.549407   \n",
      "std      6.860353    0.115878    0.702617   28.148862    2.105710    8.707259   \n",
      "min      0.460000    0.385000    3.561000    2.900000    1.129600    1.000000   \n",
      "25%      5.190000    0.449000    5.885500   45.025000    2.100175    4.000000   \n",
      "50%      9.690000    0.538000    6.208500   77.500000    3.207450    5.000000   \n",
      "75%     18.100000    0.624000    6.623500   94.074999    5.188425   24.000000   \n",
      "max     27.740000    0.871000    8.780000  100.000000   12.126500   24.000000   \n",
      "\n",
      "              tax     ptratio       lstat       cmedv  \n",
      "count  506.000000  506.000000  506.000000  506.000000  \n",
      "mean   408.237154   18.455534   12.653063   22.528854  \n",
      "std    168.537116    2.164946    7.141062    9.182176  \n",
      "min    187.000000   12.600000    1.730000    5.000000  \n",
      "25%    279.000000   17.400000    6.950000   17.025000  \n",
      "50%    330.000000   19.050000   11.360000   21.200001  \n",
      "75%    666.000000   20.200001   16.954999   25.000000  \n",
      "max    711.000000   22.000000   37.970001   50.000000  \n"
     ]
    }
   ],
   "source": [
    "# We can view summary statistics about the data by calling the \"describe()\" method of \"data\"\n",
    "# Def: Method - take an action on the data (a verb)\n",
    "\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Col Name                                         Definition\n",
      "0          town                                       name of town\n",
      "1         tract                                       census tract\n",
      "2     longitude                               long of census tract\n",
      "3      latitude                                lat of census tract\n",
      "4         crime                      per capita crime rate by town\n",
      "5   residential  proportion of residential land zoned for lots ...\n",
      "6    industrial   proportion of non-retail business acres per town\n",
      "7         river  Charles River dummy variable (= 1 if tract bou...\n",
      "8           nox  nitric oxides concentration (parts per 10 mill...\n",
      "9         rooms               average number of rooms per dwelling\n",
      "10        older  proportion of owner-occupied units older than ...\n",
      "11     distance  weighted distances to five Boston employment c...\n",
      "12      highway          index of accessibility to radial highways\n",
      "13          tax           full-value property-tax rate per $10,000\n",
      "14      ptratio  the ratio of students to teachers in primary a...\n",
      "15        lstat  % of homeowners in the neighborhood considered...\n",
      "16        cmedv    Median value of owner-occupied homes in $1000's\n"
     ]
    }
   ],
   "source": [
    "#What do all these fields mean? Let's use the data dictionary to find out\n",
    "\n",
    "data_dict = pd.read_csv(data_dict_path)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**This last value, *cmedv*, is what we would like to predict using a machine learning. Before we can predict, we need to make sure we clean the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NAs, NaNs, etc. \n",
    "any(data.isnull().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data clean!\n"
     ]
    }
   ],
   "source": [
    "# Clean the data - do all of this at once \n",
    "\n",
    "data.fillna(0)\n",
    "data['river'].replace('no', False, inplace = True)\n",
    "data['river'].replace('yes', True, inplace = True)\n",
    "data.drop(['town'], axis = 1, inplace = True)\n",
    "\n",
    "print(\"Data clean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>crime</th>\n",
       "      <th>residential</th>\n",
       "      <th>industrial</th>\n",
       "      <th>river</th>\n",
       "      <th>nox</th>\n",
       "      <th>rooms</th>\n",
       "      <th>older</th>\n",
       "      <th>distance</th>\n",
       "      <th>highway</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>cmedv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>-70.955002</td>\n",
       "      <td>42.255001</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>False</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.199997</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>-70.949997</td>\n",
       "      <td>42.287498</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>False</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.900002</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>-70.935997</td>\n",
       "      <td>42.283001</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>False</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.099998</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2031</td>\n",
       "      <td>-70.928001</td>\n",
       "      <td>42.292999</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.799999</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2032</td>\n",
       "      <td>-70.921997</td>\n",
       "      <td>42.298000</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.200001</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tract  longitude   latitude    crime  residential  industrial  river  \\\n",
       "0   2011 -70.955002  42.255001  0.00632         18.0        2.31  False   \n",
       "1   2021 -70.949997  42.287498  0.02731          0.0        7.07  False   \n",
       "2   2022 -70.935997  42.283001  0.02729          0.0        7.07  False   \n",
       "3   2031 -70.928001  42.292999  0.03237          0.0        2.18  False   \n",
       "4   2032 -70.921997  42.298000  0.06905          0.0        2.18  False   \n",
       "\n",
       "     nox  rooms      older  distance  highway  tax    ptratio  lstat  \\\n",
       "0  0.538  6.575  65.199997    4.0900        1  296  15.300000   4.98   \n",
       "1  0.469  6.421  78.900002    4.9671        2  242  17.799999   9.14   \n",
       "2  0.469  7.185  61.099998    4.9671        2  242  17.799999   4.03   \n",
       "3  0.458  6.998  45.799999    6.0622        3  222  18.700001   2.94   \n",
       "4  0.458  7.147  54.200001    6.0622        3  222  18.700001   5.33   \n",
       "\n",
       "       cmedv  \n",
       "0  24.000000  \n",
       "1  21.600000  \n",
       "2  34.700001  \n",
       "3  33.400002  \n",
       "4  36.200001  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average housing price (in 1980) in Boston was $22,528.85\n"
     ]
    }
   ],
   "source": [
    "# Add a column for the average cmedv\n",
    "\n",
    "val_mean = data['cmedv'].mean()*1000\n",
    "print('The average housing price (in 1980) in Boston was ${:,.2f}'.format(val_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Side Note - In most applications of data science and ML, we would take a closer look at cleaning the data. Data gathering and cleansing usually consumes +80% of the DS/ML process; however, this dataset happened to be extremely clean when it was retrieved from its source online.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Decision Tree - The Building Block of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tree_joke.jpg\" height=\"500\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the columns to be used as inputs (X) are referred to as the **features**, and the output (y) value is referred to as the **target** or the **label**.\n",
    "<br>\n",
    "\n",
    "Since we are given the target/label values in this dataset, the type of machine learning we will be doing is called **supervised**. \n",
    "<br>\n",
    "In particular, we will be using a random forest. Before we jump into that, we need to understand the basic building block of that model, known as the decision tree. \n",
    "<br>\n",
    "<br>\n",
    "A decision tree is one of the easiest machine learning model to comprehend, since it is easily visualized. The below graphic is an example of a simple decision tree. Notice that each *node* contains a yes/no question, and each *branch* leads to a new node, unless it leads to an answer. These answers are called *leaves* or *leaf nodes*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/decision_tree_example.jpg\" width=\"500\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are these questions determined? The decision tree is given several features (inputs) and determines which questions to ask to *gain the most information from the oucome*, i.e., to increase **information gain**. You can think of a decision tree like a game of *Guess Who?*. Each round, you ask one question in order to get the most information out of the opposite player. \n",
    "<br>\n",
    "<br>\n",
    "For example, a popular first round question is, *\"Is your character a man or woman?\"*. This gives you a lot more information than asking *\"Is your character Joe?\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/guess_who.jpg\" width=\"500\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform supervised learning, we will **train** (aka, fit) our model, and then **test** our model to see how accurate it is. We do this by first dividing the data into the **training data** and the **testing data**. In order for our model to be trained adequately, we would like it to have as much data as possible. Therefore, we take 80% of our current dataset to be the training data, and the remaining 20% to be the testing data. This is somewhat arbitrary, but the split usually lies around 75 / 25 or 80 / 20. \n",
    "<br>\n",
    "\n",
    "Also recall from above that the input (X) values are referred to as **features** and the output (y) values are referred to as **targets** or **labels**. We need to store the columns in our dataset into these variables before we can split our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/splitting_data.png\" width=\"700\" height=\"700\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first split our data into **feaures** and **labels**, and then **training data** and **testing data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Features vs. Labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the cmedv column - the features are all the columns except this one\n",
    "features = data.drop(['cmedv'], axis=1)\n",
    "feature_list = list(data.drop(['cmedv'], axis=1).columns)\n",
    "\n",
    "# Drop all columns that aren't cmedv - cmedv is the only label\n",
    "labels = data.drop(data.columns[data.columns != 'cmedv'], axis = 1)\n",
    "\n",
    "# Convert to numpy arrays - these are similar to dataframes but have less structure. sklearn can only take numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training Data vs. Testing Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to split the data and store the data into variables. \n",
    "# Notice we specify test_size = 0.2. This gives the 80/20 split as explained above\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Supervised Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, a decision tree is a supervised learnin model, since we have labels that help the algorithm learn. The following picture depicts the supervised learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Supervised_Learning.png\" width=\"700\" height=\"700\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sci-kit learn 3 lines of code to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn import tree\n",
    "\n",
    "# instantiate \n",
    "decision_tree = tree.DecisionTreeRegressor(random_state = 8)\n",
    "\n",
    "# train/fit\n",
    "decision_tree = decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our *Trained Model* looks like by converting the tree into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View picture after converting to png (I did this already)\n",
    "!\"images/tree.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Side-Note: To convert this dot file on your own, you need to use some command line magic I converted the file beforehand, so you can view the tree by running this code block.\n",
    "For anyone interested, the command line function is below (make sure you are cd'd into the random_forest/images directory and are in the dm_ml environment)*\n",
    "\n",
    ">\\> *dot -Tpng tree.dot -o tree.png*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the labels from the testing data to generate predictions on the housing prices. Let's see what the model comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual value</th>\n",
       "      <th>predicted value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[28.2000008]</td>\n",
       "      <td>30.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[23.8999996]</td>\n",
       "      <td>28.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[16.600000400000003]</td>\n",
       "      <td>18.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22.0]</td>\n",
       "      <td>20.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20.7999992]</td>\n",
       "      <td>16.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[23.0]</td>\n",
       "      <td>19.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[27.899999600000005]</td>\n",
       "      <td>26.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[14.5]</td>\n",
       "      <td>19.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[21.5]</td>\n",
       "      <td>18.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[22.6000004]</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[23.7000008]</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[31.2000008]</td>\n",
       "      <td>30.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[19.2999992]</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[19.3999996]</td>\n",
       "      <td>18.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[19.3999996]</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[27.899999600000005]</td>\n",
       "      <td>23.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[13.8999996]</td>\n",
       "      <td>13.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[50.0]</td>\n",
       "      <td>37.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[24.1000004]</td>\n",
       "      <td>22.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[14.6000004]</td>\n",
       "      <td>17.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[16.2000008]</td>\n",
       "      <td>18.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[15.6000004]</td>\n",
       "      <td>13.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[23.7999992]</td>\n",
       "      <td>25.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[25.0]</td>\n",
       "      <td>25.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[23.5]</td>\n",
       "      <td>24.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[8.30000019]</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[13.5]</td>\n",
       "      <td>13.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[17.5]</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[43.0999985]</td>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[11.5]</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[21.8999996]</td>\n",
       "      <td>20.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[21.0]</td>\n",
       "      <td>19.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[20.3999996]</td>\n",
       "      <td>20.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>[21.7999992]</td>\n",
       "      <td>16.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[50.0]</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[22.0]</td>\n",
       "      <td>24.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[23.2999992]</td>\n",
       "      <td>24.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[37.2999992]</td>\n",
       "      <td>28.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[18.0]</td>\n",
       "      <td>17.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[19.2000008]</td>\n",
       "      <td>20.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[34.9000015]</td>\n",
       "      <td>33.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[13.3999996]</td>\n",
       "      <td>9.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[22.8999996]</td>\n",
       "      <td>23.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[22.5]</td>\n",
       "      <td>23.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[13.0]</td>\n",
       "      <td>17.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[24.6000004]</td>\n",
       "      <td>25.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[18.2999992]</td>\n",
       "      <td>16.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[18.1000004]</td>\n",
       "      <td>17.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[23.8999996]</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[50.0]</td>\n",
       "      <td>48.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[13.6000004]</td>\n",
       "      <td>15.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[22.8999996]</td>\n",
       "      <td>18.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[10.8999996]</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[18.8999996]</td>\n",
       "      <td>18.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[22.3999996]</td>\n",
       "      <td>25.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[22.8999996]</td>\n",
       "      <td>22.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[44.7999992]</td>\n",
       "      <td>37.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[21.7000008]</td>\n",
       "      <td>21.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[10.1999998]</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[15.3999996]</td>\n",
       "      <td>23.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual value  predicted value\n",
       "0            [28.2000008]        30.100000\n",
       "1            [23.8999996]        28.700001\n",
       "2    [16.600000400000003]        18.900000\n",
       "3                  [22.0]        20.900000\n",
       "4            [20.7999992]        16.799999\n",
       "5                  [23.0]        19.600000\n",
       "6    [27.899999600000005]        26.400000\n",
       "7                  [14.5]        19.600000\n",
       "8                  [21.5]        18.799999\n",
       "9            [22.6000004]        23.900000\n",
       "10           [23.7000008]        25.000000\n",
       "11           [31.2000008]        30.100000\n",
       "12           [19.2999992]        20.000000\n",
       "13           [19.3999996]        18.900000\n",
       "14           [19.3999996]        20.000000\n",
       "15   [27.899999600000005]        23.100000\n",
       "16           [13.8999996]        13.100000\n",
       "17                 [50.0]        37.599998\n",
       "18           [24.1000004]        22.900000\n",
       "19           [14.6000004]        17.799999\n",
       "20           [16.2000008]        18.500000\n",
       "21           [15.6000004]        13.100000\n",
       "22           [23.7999992]        25.100000\n",
       "23                 [25.0]        25.200001\n",
       "24                 [23.5]        24.700001\n",
       "25           [8.30000019]         8.400000\n",
       "26                 [13.5]        13.100000\n",
       "27                 [17.5]        19.000000\n",
       "28           [43.0999985]        43.500000\n",
       "29                 [11.5]        12.500000\n",
       "..                    ...              ...\n",
       "72           [21.8999996]        20.799999\n",
       "73                 [21.0]        19.600000\n",
       "74           [20.3999996]        20.100000\n",
       "75           [21.7999992]        16.799999\n",
       "76                 [50.0]        50.000000\n",
       "77                 [22.0]        24.799999\n",
       "78           [23.2999992]        24.400000\n",
       "79           [37.2999992]        28.500000\n",
       "80                 [18.0]        17.100000\n",
       "81           [19.2000008]        20.299999\n",
       "82           [34.9000015]        33.200001\n",
       "83           [13.3999996]         9.600000\n",
       "84           [22.8999996]        23.100000\n",
       "85                 [22.5]        23.200001\n",
       "86                 [13.0]        17.100000\n",
       "87           [24.6000004]        25.200001\n",
       "88           [18.2999992]        16.799999\n",
       "89           [18.1000004]        17.799999\n",
       "90           [23.8999996]        22.000000\n",
       "91                 [50.0]        48.799999\n",
       "92           [13.6000004]        15.200000\n",
       "93           [22.8999996]        18.200001\n",
       "94           [10.8999996]        16.100000\n",
       "95           [18.8999996]        18.200001\n",
       "96           [22.3999996]        25.100000\n",
       "97           [22.8999996]        22.200001\n",
       "98           [44.7999992]        37.599998\n",
       "99           [21.7000008]        21.200001\n",
       "100          [10.1999998]        16.100000\n",
       "101          [15.3999996]        23.200001\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "tree_predictions = decision_tree.predict(X_test)\n",
    "\n",
    "# Format and print\n",
    "tree_predictions = pd.Series(tree_predictions)\n",
    "pd.DataFrame(data = {'predicted value': tree_predictions, 'actual value':list(y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "As you can see, the predicted values differ from the y_values for each row; the accuracy of each row differs. To better understand our model, however, we want the overall accuracy of all the rows, using RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rmse_formula.png\" width=\"200\" height=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the actual y values from the test data (y_test) next to the model's predicted values (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree's TEST RMSE is 3.7 or $3,653.28\n"
     ]
    }
   ],
   "source": [
    "# Import some functions from sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate the ROOT-mse (mean square error), aka the RMSE\n",
    "tree_rmse = np.sqrt(mean_squared_error(y_test, tree_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(\"Our tree's TEST RMSE is {:.2} or ${:,.2f}\".format(tree_rmse, tree_rmse*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like a pretty good accuracy, except we **overfit** the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree's TRAIN RMSE is 0.00.\n"
     ]
    }
   ],
   "source": [
    "# What happens if we try to predict the y's on our training data?\n",
    "predictions_training = decision_tree.predict(X_train)\n",
    "\n",
    "# Calculate the RMSE\n",
    "training_rmse = mean_squared_error(y_train, predictions_training)\n",
    "\n",
    "print(\"Our tree's TRAIN RMSE is {:.2f}.\".format(training_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By fitting the model \"out of the box\", we allowed the tree to grow as large as possible (we can see this because there was absolutely no error when it predicted the y values for the training data... the model predicted every y value exactly.).This causes the tree to overfit the data. \n",
    "\n",
    "Overfitting is when the model follows the *\"noise\"* of the **training data** too closely, and therefore won't predict general input data later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/overfitting_underfitting.png\" width=\"700\" height=\"700\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways to combat overfitting by tuning the model. One way to do this is decrease the depth of the tree (either during or after fitting - research *pruning*). We won't get into that here, instead we will show another way to more accurately (and powerfully) predict our outcomes - the random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Side note - Please note that if we set the random states to different numbers, the result would be different, however While this decision tree is quite accurate, we can possibly improve accuracy using the random forest model The random forest model essentially builds multiple decision trees, takes the outputs from all of those trees, and determines the best prediction by taking the average (regression) or the mode (classification) of the outputs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/random-forest.jpg\" width=\"700\" height=\"700\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest is an **ensemble model** i.e., it combines multiple models into one larger model. By combining multiple decision trees, the random forest is able to improve the prediction accuracy. \n",
    "\n",
    "<br> The random forest combines multiple decision trees by using a concept called **bootstrap aggregating**, or **bagging** for short. This method builds multiple (usually 1,000's) decision trees during the *Train the Model* step. When we *Test the Model*, each decision tree predicts the output and the random forest combines all the outputs into a *single* output. It does this by either taking a majority vote (in classification) or by aggregating the values (in regression, which is our case) by use of a mean, median, etc. \n",
    "\n",
    "This is all done behind the scenes within sklearn. The same 3-step process is used (recall that the data was originally split above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsattgast\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "           oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, we import, instantiate, and then fit\n",
    "# Here, n_estimators is the number of decision trees in our random forest\n",
    "\n",
    "# import \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# instantiate \n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 10)\n",
    "\n",
    "# train/fit\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual value</th>\n",
       "      <th>predicted values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[28.2000008]</td>\n",
       "      <td>29.8702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[23.8999996]</td>\n",
       "      <td>26.5618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[16.600000400000003]</td>\n",
       "      <td>18.5152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22.0]</td>\n",
       "      <td>21.4070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20.7999992]</td>\n",
       "      <td>19.6283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual value  predicted values\n",
       "0          [28.2000008]           29.8702\n",
       "1          [23.8999996]           26.5618\n",
       "2  [16.600000400000003]           18.5152\n",
       "3                [22.0]           21.4070\n",
       "4          [20.7999992]           19.6283"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's predict and see the predictions next to the actual y values\n",
    "\n",
    "# predict\n",
    "rf_predictions = rf.predict(X_test)\n",
    "\n",
    "# format and print\n",
    "pd.DataFrame(data = {'predicted values':rf_predictions, 'actual value': list(y_test)}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image file\n",
    "!(\"images/tree_from_random_forest_output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree's RMSE is 2.8 or $2,787.19. \n",
      "...getting better\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy (RMSE)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "\n",
    "# Format and print\n",
    "print(\"Our tree's RMSE is {:.2} or ${:,.2f}. \\n...getting better\".format(rf_rmse, rf_rmse*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we see that simply using random forest is better than a single decision tree, there is still room for improvement. These next 2 sections will show you some techniques to both simplify and tune your model in order to improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Forest Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which factors of a neighborhood influence it's price the most. We can do this using a few more complex techniques in Python. \n",
    "<br>\n",
    "\n",
    "I won't be getting into these and I am also going to use some code that was written by William Koehrsen in his article that can be found here: https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: lstat                Importance: 0.5\n",
      "Variable: rooms                Importance: 0.29\n",
      "Variable: distance             Importance: 0.05\n",
      "Variable: crime                Importance: 0.04\n",
      "Variable: longitude            Importance: 0.02\n",
      "Variable: nox                  Importance: 0.02\n",
      "Variable: older                Importance: 0.02\n",
      "Variable: tract                Importance: 0.01\n",
      "Variable: latitude             Importance: 0.01\n",
      "Variable: industrial           Importance: 0.01\n",
      "Variable: tax                  Importance: 0.01\n",
      "Variable: ptratio              Importance: 0.01\n",
      "Variable: residential          Importance: 0.0\n",
      "Variable: river                Importance: 0.0\n",
      "Variable: highway              Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like lstat and rooms make up about 80% of the importance in predicting the housing price.<br>\n",
    "Does this make sense? It is always improtant to look at your model output and determine if it logically matches the context of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cumulative importance</th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lstat</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>rooms</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.88</td>\n",
       "      <td>crime</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>longitude</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.92</td>\n",
       "      <td>nox</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.94</td>\n",
       "      <td>older</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.95</td>\n",
       "      <td>tract</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.96</td>\n",
       "      <td>latitude</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.97</td>\n",
       "      <td>industrial</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.98</td>\n",
       "      <td>tax</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.99</td>\n",
       "      <td>ptratio</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.99</td>\n",
       "      <td>residential</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.99</td>\n",
       "      <td>river</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.99</td>\n",
       "      <td>highway</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cumulative importance     features  importance\n",
       "0                    0.50        lstat        0.50\n",
       "1                    0.79        rooms        0.29\n",
       "2                    0.84     distance        0.05\n",
       "3                    0.88        crime        0.04\n",
       "4                    0.90    longitude        0.02\n",
       "5                    0.92          nox        0.02\n",
       "6                    0.94        older        0.02\n",
       "7                    0.95        tract        0.01\n",
       "8                    0.96     latitude        0.01\n",
       "9                    0.97   industrial        0.01\n",
       "10                   0.98          tax        0.01\n",
       "11                   0.99      ptratio        0.01\n",
       "12                   0.99  residential        0.00\n",
       "13                   0.99        river        0.00\n",
       "14                   0.99      highway        0.00"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "cumulative_importances = np.round(np.cumsum(sorted_importances),2)\n",
    "\n",
    "importance_df = pd.DataFrame({'features': sorted_features, 'importance': sorted_importances, 'cumulative importance': cumulative_importances})\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick what we want our cumulative importance to be. Here I chose 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d7d68be128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will not work on your comp - need to install matplotlib!\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features = importance_df['features']\n",
    "importance =  importance_df['importance']\n",
    "cumulative_importance = importance_df['cumulative importance']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "ax.scatter(features, importance, label=\"importance\")\n",
    "ax.plot(features, cumulative_importance, label=\"cumulative importance\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cumulative importance</th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lstat</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>rooms</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.88</td>\n",
       "      <td>crime</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>longitude</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.92</td>\n",
       "      <td>nox</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.94</td>\n",
       "      <td>older</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.95</td>\n",
       "      <td>tract</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cumulative importance   features  importance\n",
       "0                   0.50      lstat        0.50\n",
       "1                   0.79      rooms        0.29\n",
       "2                   0.84   distance        0.05\n",
       "3                   0.88      crime        0.04\n",
       "4                   0.90  longitude        0.02\n",
       "5                   0.92        nox        0.02\n",
       "6                   0.94      older        0.02\n",
       "7                   0.95      tract        0.01"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return only enough features to give us 95% importance \n",
    "\n",
    "new_df = importance_df[importance_df['cumulative importance'] <= 0.95]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to use these features. We can re-run the random forest with only these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lstat', 'rooms', 'distance', 'crime', 'longitude', 'nox', 'older', 'tract']\n"
     ]
    }
   ],
   "source": [
    "#split the data - features vs labels\n",
    "features = data[new_df.features]\n",
    "labels = data['cmedv']\n",
    "print(list(features.columns))\n",
    "\n",
    "#convert to numpy arrays\n",
    "import numpy as np\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "#split the data - training vs testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(\n",
    "    features, labels, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "           oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import - we already did this above!\n",
    "\n",
    "# instantiate\n",
    "rf_simple = RandomForestRegressor(n_estimators = 1000, random_state = 10)\n",
    "\n",
    "# train/fit\n",
    "rf_simple.fit(X_train_simple, y_train_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual values  predictions\n",
      "0      28.200001      28.4153\n",
      "1      23.900000      26.1142\n",
      "2      16.600000      18.0141\n",
      "3      22.000000      21.6454\n",
      "4      20.799999      19.7472\n"
     ]
    }
   ],
   "source": [
    "# Predict \n",
    "rf_simple_predictions = rf_simple.predict(X_test_simple)\n",
    "\n",
    "# Format and print\n",
    "print(pd.DataFrame({'predictions': rf_simple_predictions, 'actual values': y_test_simple}).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree's RMSE is 2.8 or $2,829.21.\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy (RMSE)\n",
    "rf_simple_rmse = np.sqrt(mean_squared_error(y_test_simple, rf_simple_predictions))\n",
    "\n",
    "# Format and print\n",
    "print(\"Our tree's RMSE is {:.2} or ${:,.2f}.\".format(rf_simple_rmse, rf_simple_rmse*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that our first random forest's RMSE was $2,787.01. Our model got worse!\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "But only slightly... we lost a few % points of accuracy, but were able to cut the number of inputs into our model by about half. This proves that (1) those other inputs added almost no value, and (2) we don't always need a super complex model in machine learning. \n",
    "\n",
    "<br>\n",
    "*Side note - What we also gained here is decreased runtime - it took less computation time to get almost the same accuracy. This trade-off is extremely important in data science, especially when developing a model that will scale and/or will potentially be deployed in production.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Tuning the Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"While model parameters are learned during trainingâ€Šâ€”â€Šsuch as the slope and intercept in a linear regressionâ€Šâ€”â€Šhyperparameters must be set by the data scientist before training.\" - William Koehrsen\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [1000, 2000, 3000]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features =  ['sqrt', 'log']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [None, 1, 2, 4]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 8]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a grid\n",
    "cv_grid = {'n_estimators': n_estimators,\n",
    "           'max_features': max_features,\n",
    "           'max_depth': max_depth,\n",
    "           'min_samples_split': min_samples_split,\n",
    "           'min_samples_leaf': min_samples_leaf\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This will take some time to run....*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=2, random_state=10)\n",
    "grid_search = GridSearchCV(rf, param_grid=cv_grid, cv=5)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "grid_predictions = rf_simple.predict(X_test_simple)\n",
    "\n",
    "# Format and print\n",
    "print(pd.DataFrame({'predictions': grid_predictions, 'actual values': y_test}).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (RMSE)\n",
    "rf_grid_rmse = np.sqrt(mean_squared_error(y_test, grid_predictions))\n",
    "\n",
    "# Format and print\n",
    "print(\"Our tree's RMSE is {:.2} or ${:,.2f}.\".format(rf_grid_rmse, rf_grid_rmse*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "## Resources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/data_science.jpg\" width=\"400\" height=\"400\" align=\"right\"/>\n",
    "\n",
    "### Introductory Topics ###\n",
    "\n",
    "*How to Become a Data Science* <br>\n",
    "https://towardsdatascience.com/how-to-learn-data-science-if-youre-broke-7ecc408b53c7 <br>\n",
    "https://www.class-central.com/subject/data-science <br>\n",
    "\n",
    "*Jupyter* <br>\n",
    "https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html\n",
    "\n",
    "*Pandas* <br>\n",
    "https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n",
    "\n",
    "\n",
    "### Deep Dive Topics ###\n",
    "\n",
    "*Information Gain and Entropy* <br>\n",
    "https://www.saedsayad.com/decision_tree.htm <br>\n",
    "\n",
    "*Ensemble Models - The Power of Crowds and Aggregated Predictions* <br>\n",
    "https://www.npr.org/sections/money/2015/08/07/429720443/17-205-people-guessed-the-weight-of-a-cow-heres-how-they-did <br>\n",
    "\n",
    "*Random Forest - Feature Information* <br>\n",
    "http://explained.ai/rf-importance/index.html <br>\n",
    "http://www.scikit-yb.org/en/latest/api/features/importances.html <br>\n",
    "\n",
    "*Grid Search* <br>\n",
    "https://www.quora.com/Machine-Learning-How-does-grid-search-work <br>\n",
    "\n",
    "\n",
    "### General ####\n",
    "\n",
    "*Good Reads* <br>\n",
    "https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 <br>\n",
    "https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12 <br>\n",
    "https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d <br>\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0 <br>\n",
    "https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained <br>\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "*Data Source* <br>\n",
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
